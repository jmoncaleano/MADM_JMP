library(tidyverse)
library(nycflights13)
View(sorted_date[1024:1068,])
### ARRANGE
sorted_date <- arrange(flights, year, month, day)
tail(sorted_date)
head(arrange(flights, desc(arr_delay)))
arrange(flights, desc(dep_delay))
arrange(df, x)
arrange(df, desc(x))
View(arrange(flights, carrier))
View(sorted_date[1024:1068,])
select(flights, -(year:day))
select(flights, year, month, day)
select(flights, dep_time:arr_delay)
select(flights, dep_time:dep_delay)
arr
select(flights, dep_time:arr_delay)
select(flights, -(year:day))
select(flights, starts_with("dep"))
select(flights, ends_with("delay"))
select(flights, contains("st"))
select(flights, matches("(.)\\1"))
select(flights, num_range("x",1:5))# x1, x2, x3, x4, x5
?select
rename(flights, deptime = dep_time,
año = year, mes = month, dia = day)
select(flights, deptime = dep_time)
select(flights, time_hour, distance, air_time, everything())
sorted_date
rename(flights, deptime = dep_time,
año = year, mes = month, dia = day)
### MUTATE
flights_new <- select(flights,
year:day,
ends_with("delay"),
distance,
air_time)
mutate(flights_new,
time_gain = arr_delay - dep_delay,    #diff_t (min)
air_time_hour = air_time/60,
flight_speed = distance/air_time_hour, #v = s/t (km/h)
time_gain_per_hour = time_gain / air_time_hour
) -> flights_new
flights_new
flights_new
transmute(flights_new,
time_gain = arr_delay - dep_delay,
air_time_hour = air_time/60,
flight_speed = distance / air_time_hour,
time_gain_per_hour = time_gain / air_time_hour) -> data_from_flights
# * Operaciones aritméticas: +, -, *, /, ^  (hours + 60 * minutes)
# * Agregados de funciones: x/sum(x) : proporición sobre el total
#                           x - mean(x): distancia respecto de media
#                           (x - mean(x))/sd(x): tipificación
#                           (x - min(x))/(max(x) - min(x)): estandarizar entre [0,1]
# * Aritmética modular: %/%-> cociente de la división entera, %% -> resto de la división entera
#                       x == y * (x%/%y) + (x%%y)
transmute(flights,
air_time,
hour_air = air_time %/% 60,
minute_air = air_time %% 60
)
# * Logaritmos: log() -> logaritmo en base e, log2(), log10()
# * Offsets: lead()->mueve hacia la izquierda, lag()->mueve hacia la derecha
df <- 1:12
df
lag(df)
lead(df)
# * Funcions acumulativas: cumsum(), cumprod(), cummin(), cummax(), cummean()
df
cumsum(df)
cumprod(df)
cummin(df)
cummax(df)
cummean(df)
# * Comparaciones lógicas: >, >=, <, <=, ==, !=
transmute(flights,
dep_delay,
has_been_delayed = (dep_delay >0)
)
# * Rakings:min_rank()
df <- c(7,1,2,5,3,3,8,NA,3,4,-2)
df
min_rank(df)
df
min_rank(desc(df))
row_number(df)
dense_rank(df)
percent_rank(df)
cume_dist(df)
delay <- filter(delay, count>100, dest != "HNL")
ggplot(data = delay, mapping = aes(x=dist, y = delay)) +
geom_point(aes(size = count), alpha = 0.2) +
geom_smooth(se = F) +
geom_text(aes(label = dest), alpha = 0.3)
percent_rank(df)
cume_dist(df)
ntile(df, n = 4)
transmute(flights,
dep_delay,
ntile(dep_delay, n = 100))
#Ejercicio 1
transmute(flights,
dep_time, sched_dep_time,
new_dep_time = 60*dep_time %/% 100 + dep_time %% 100 ,
new_sched_dep_time = 60*sched_dep_time %/% 100 + sched_dep_time %% 100
)
#Ejercicio 2
transmute(flights,
air_time,
new_dep_time = 60*dep_time %/% 100 + dep_time %% 100 ,
new_arr_time = 60*arr_time %/% 100 + arr_time %% 100,
new_air_time = new_arr_time - new_dep_time)
#Ejercicio 3
transmute(flights,
new_dep_time = 60*dep_time %/% 100 + dep_time %% 100 ,
new_sched_dep_time = 60*sched_dep_time %/% 100 + sched_dep_time %% 100,
new_delay = new_dep_time - new_sched_dep_time,
dep_delay,
new_delay==dep_delay)
#Ejercicio 4
arrange(mutate(flights,
r_delay = min_rank(dep_delay)),
r_delay
)[1:10,]
summarise(flights, delay = mean(dep_delay, na.rm = T))
by_month_group <- group_by(flights, year, month)
summarise(by_month_group, delay = mean(dep_delay, na.rm = T))
by_day_group <- group_by(flights, year, month, day)
summarise(by_day_group,
delay = mean(dep_delay, na.rm = T),
median = median(dep_delay, na.rm = T),
min = min(dep_delay, na.rm = T)
)
mutate(summarise(group_by(flights, carrier),
delay = mean(dep_delay, na.rm = T)),
sorted = min_rank(delay)
)
### PIPES
group_by_dest <- group_by(flights, dest)
delay <- summarise(group_by_dest,
count = n(),
dist = mean(distance, na.rm = T),
delay = mean(arr_delay, na.rm = T)
)
delay <- filter(delay, count>100, dest != "HNL")
ggplot(data = delay, mapping = aes(x=dist, y = delay)) +
geom_point(aes(size = count), alpha = 0.2) +
geom_smooth(se = F) +
geom_text(aes(label = dest), alpha = 0.3)
delays <- flights %>%
group_by(dest) %>%
summarise(
count = n(),
dist = mean(distance, na.rm = T),
delay = mean(arr_delay, na.rm = T)
) %>%
filter(count > 100, dest!="HNL")
flights %>%
group_by(year, month, day) %>%
summarise(mean = mean(dep_delay, na.rm  = T),
median = median(dep_delay, na.rm = T),
sd = sd(dep_delay, na.rm = T),
count = n()
)
flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay)) %>%
group_by(year, month, day) %>%
summarise(mean = mean(dep_delay, na.rm  = T),
median = median(dep_delay, na.rm = T),
sd = sd(dep_delay, na.rm = T),
count = n()
)
delay_numtail <- not_cancelled %>%
group_by(tailnum) %>%
summarise(delay = mean(arr_delay))
ggplot(data = delay_numtail, mapping = aes(x = delay)) +
geom_freqpoly(binwidth = 5)
ggplot(data = delay_numtail, mapping = aes(x = delay)) +
geom_histogram(binwidth = 5)
flights_new %>%
transmute(flights_new,
time_gain = arr_delay - dep_delay,
air_time_hour = air_time/60,
flight_speed = distance / air_time_hour,
time_gain_per_hour = time_gain / air_time_hour) -> data_from_flights
flights_new
flights_new %>%
filter(!is.na(time_gain_per_hour)) %>%
ggplot() + geom_histogram(mapping = aes(x=time_gain_per_hour, y=count()))
flights_new %>%
filter(!is.na(time_gain_per_hour)) %>%
ggplot() + geom_histogram(mapping = aes(x=time_gain_per_hour, y=count()))
getwd()
Data=read.table("facebook_sample_anon.txt", quote="\"", comment.char="")
View(data)
View(Data)
facebook=graph_from_data_frame(d=Data, directed=TRUE)
library(knitr)
library(igraph)
facebook=graph_from_data_frame(d=Data, directed=TRUE)
plot(facebook)
is_connected(facebook)
```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=8, fig.height=8, fig.align="center", echo=TRUE, warning=FALSE, message=FALSE)
library(knitr)
library(igraph)
gorder(facebook)
gsize(facebook)
edge_density(facebook)
make_ring(250)
anillo <- make_ring(250)
plot(anillo)
average.path.length(anillo)
?add.edges
add.edges(facebook(1,250))
add.edges(facebook(1,249))
add.edges(facebook, c(1,249))
g1 <- add.edges(facebook, c(1,249))
average.path.length(g1)
g1 <- add.edges(facebook, c(3,249:2))
?sapply
?sapply
?sapply
?sample
?sample
valor <- sample(3:249)
valor
valor <- sample(3:249, 1)
valor
g1 <- add.edges(anillo, 1, valor)
g1 <- add.edges(anillo, c(1,valor)
g1 <- add.edges(anillo, c(1,valor))
average.path.length(g1)
#valor <- sample(3:249, 1)
lista <- 3:249
lista
?apply
valor <- sample(3:249, 1)
g1 <- add.edges(anillo, c(1,valor))
dist <- average.path.length(g1)
dist
?sapply
media = c()
for (i in 3:249){
g1 <- add.edges(anillo, c(1, i))
media <- c(media, average.path.length(g1))
}
media
mean(media)
media = c()
for (i in 2:249){
g1 <- add.edges(anillo, c(1, i))
media <- c(media, average.path.length(g1))
}
media
mean(media)
media = c()
for (i in 1:249){
g1 <- add.edges(anillo, c(1, i))
media <- c(media, average.path.length(g1))
}
media
mean(media)
media = c()
for (i in 3:249){
g1 <- add.edges(anillo, c(1, i))
media <- c(media, average.path.length(g1))
}
media
mean(media)
plot(g1)
install.packages("MonteCarlo")
library(MonteCarlo)
?MonteCarlo
set.seed(10)
aleatorio <- sample(3:249, 1)
aleatorio
?sample
?rep()
?rep
funcion1 <- function(){
set.seed(10)
aleatorio <- sample(3:249, 1)
g1 <- add.edges(anillo, c(1, aleatorio))
}
?rep
?sample
MonteCarlo(funcion1, 100)
?MonteCarlo
MonteCarlo(funcion1, 100, c())
MonteCarlo(funcion1, 100)
funcion1 <- function(){
set.seed(10)
aleatorio <- sample(3:249, 1)
g1 <- add.edges(anillo, c(1, aleatorio))
dist <- average.path.length(g1)
}
?MonteCarlo
MonteCarlo(funcion1, 100)
param_list=list("n"=n_grid, "loc"=loc_grid, "scale"=scale_grid)
MonteCarlo(funcion1, 100, param_list=param_list)
param_list=list("n"=10, "loc"=2, "scale"=2)
MonteCarlo(funcion1, 100, param_list=param_list)
MonteCarlo(funcion1, 100, param_list=anillo)
funcion1 <- function(){
set.seed(10)
aleatorio <- sample(3:249, 1)
g1 <- add.edges(anillo, c(1, aleatorio))
dist <- average.path.length(g1)
return(dist)
}
#?MonteCarlo
param_list=list("n"=10, "loc"=2, "scale"=2)
MonteCarlo(funcion1, 100, param_list=anillo)
#?MonteCarlo
param_list=list(10, 2, =2)
#?MonteCarlo
param_list=list(10, 2, 2)
MonteCarlo(funcion1, 100, param_list=anillo)
#?MonteCarlo
param_list=list(1, 2, 2)
MonteCarlo(funcion1, 100, param_list=anillo)
library(wooldridge)
data("wage1")
data
View(wage1)
wage=wage1$wage
educ=wage1$educ
exper=wage1$exper
fit1b=lm(lwage ~ educ + exper + I(exper^2), data = wage1)
summary(fit1b)
female=wage1$female
tenure=wage1$tenure
fit2b=lm(lwage ~ female + (female*educ)+ educ + exper + I(exper^2) + tenure + I(tenure^2), data = wage1)
summary(fit2b)
fit2c=lm(lwage ~ female + I(female*I(educ-12.5))+ educ + exper + I(exper^2) + tenure + I(tenure^2), data = wage1)
summary(fit2c)
fit2b=lm(lwage ~ female + I(female*educ)+ educ + exper + I(exper^2) + tenure + I(tenure^2), data = wage1)
summary(fit2b)
fit2b=lm(lwage ~ female + I(female*educ)+ educ + exper + I(exper^2) + tenure + I(tenure^2), data = wage1)
summary(fit2b)
fit2b=lm(lwage ~ female + educ + exper + I(exper^2) + tenure + I(tenure^2), data = wage1)
summary(fit2b)
fit2c=lm(lwage ~ female + educ + exper + I(exper^2) + tenure + I(tenure^2), data = wage1)
summary(fit2c)
fit2c=lm(lwage ~ female + educ + exper + I(exper^2) + tenure + I(tenure^2), data = wage1)
summary(fit2c)
summary(fit2b)
fit2c=lm(lwage ~ female + I(female*I(educ-12.5))+ educ + exper + I(exper^2) + tenure + I(tenure^2), data = wage1)
summary(fit2c)
fit2b=lm(lwage ~ female + I(female*educ)+ educ + exper + I(exper^2) + tenure + I(tenure^2), data = wage1)
summary(fit2b)
fit2c=lm(lwage ~ female + I(female*I(educ-12.5))+ educ + exper + I(exper^2) + tenure + I(tenure^2), data = wage1)
summary(fit2c)
data("bwght")
View(data)
View(data)
data("bwght").head(10)
data("bwght").head()
bwght
cgis=bwght$cgis
faminc=bwght$faminc
parity=bwght$parity
male=bwght$male
white=bwght$white
fit1b=lm(lbwght ~ cgis + lm(faminc) + parity + male + white, data = bwght)
fit1b=lm(lbwght ~ cgis + faminc + parity + male + white, data = bwght)
fit1b=lm(lbwght ~ cgis + lfaminc + parity + male + white, data = bwght)
summary(fit1b)
fit6=lm(lbwght ~ cgis + lfaminc + parity + male + white, data = bwght)
library(wooldridge)
data("bwght")
cgis=bwght$cgis
faminc=bwght$faminc
parity=bwght$parity
male=bwght$male
white=bwght$white
fit6=lm(lbwght ~ cgis + lfaminc + parity + male + white, data = bwght)
is.na(cgis)
fit6=lm(lbwght ~ cgis + lfaminc + parity + male + white, data = bwght)
summary(fit1b)
summary(fit6)
fit6=lm(lbwght ~ cgis + lfaminc + parity + male + white, data = bwght)
data=na.omit("bwght")
fit6=lm(lbwght ~ cgis + lfaminc + parity + male + white, data = bwght)
cgis=bwght$cgis
faminc=bwght$faminc
parity=bwght$parity
male=bwght$male
white=bwght$white
fit6=lm(lbwght ~ cgis + lfaminc + parity + male + white, data = bwght)
library(wooldridge)
data=na.omit("bwght")
cgis=bwght$cgis
faminc=bwght$faminc
parity=bwght$parity
male=bwght$male
white=bwght$white
fit6=lm(lbwght ~ cgis + lfaminc + parity + male + white, data = bwght)
library(wooldridge)
data("wage2")
head(wage2)
fit1=lm(lwage ~ educ, data = wage2)
summarise(fit1)
summary(fit1)
summary(fit1)
head(wage2)
fit2=lm(educ ~ sibs, data = wage2)
summary(fit2)
fit3=fit2$fitted.values
fit4=lm(lwage ~ fit3, data = wage2)
summary(fit4)
fit5=ivreg(lwage  ~ educ | sibs, data = wage2)
library(AER)
fit5=ivreg(lwage  ~ educ | sibs, data = wage2)
summary(fit5)
summary(fm, vcov=sandwich, df=Inf, diagnostics= TRUE)
summary(fit5, vcov = sandwich, df = Inf, diagnostics = TRUE)
summary(fit4)
summary(fit5, vcov = sandwich, df = Inf, diagnostics = TRUE)
summary(fit4)
summary(fit5, vcov = sandwich, df = Inf, diagnostics = TRUE)
fit6=ivreg(lwage  ~ educ | bthord, data = wage2)
head(wage2)
fit6=ivreg(lwage  ~ educ | brthord, data = wage2)
summary(fit6)
fit6=lm(educ ~ brthord, data = wage2)
summary(fit6)
fit7=lm(educ  ~ fit6, data = wage2)
summary(fit7)
fit6=lm(educ ~ brthord, data = wage2)
summary(fit6)
fit7=fit6$fitted.values
fit8=lm(lwage  ~ fit7, data = wage2)
fit6=lm(educ ~ brthord, data = wage2)
summary(fit6)
fit7=fit6$fitted.values
fit8=lm(lwage  ~ fit7, data = wage2)
fit6=lm(educ ~ brthord, data = wage2)
summary(fit6)
fit7=fit6$fitted.values
fit8=lm(lwage ~ fit7, data = wage2)
summary(fit8)
fit7=lm(lwage ~ fit6$fitted.values, data = wage2)
fit9=ivreg(lwage  ~ educ + sibs | brthord, data = wage2)
library(wooldridge)
library(AER)
data("wage2")
head(wage2)
fit6=lm(educ ~ brthord, data = wage2)
summary(fit6)
fit7=fit6$fitted.values
fit8=lm(lwage ~ fit7, data = wage2)
data("murder")
head(murder)
attach("murder")
attach(murder)
head(murder)
datos <- murder[which(year>87),]
fit <- lm(cmrdrte ~ cexec + cunem, data = na.omit(murder))
summary(fit)
fit2 <- lm(cmrdrte ~ cexec_1 + cunem, data = na.omit(murder))
fit1 <- lm(cmrdrte ~ cexec_1 + cunem, data = na.omit(murder))
summary(fit1)
fit2=ivreg(cmrdrte  ~ cexec | cexec_1, data = na.omit(murder))
summary(fit2)
summary(fit2, vcov = sandwich, fd = Inf, diagnostics = TRUE)
